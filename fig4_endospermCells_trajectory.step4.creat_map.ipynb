{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_point = [\"1_9_11h\",\"2_28h\", \"3_48h\", \"4_globular\", \"5_heart\", \"6_torpedo\", \"7_bent\", \"8_cotyledon\", \"9_late_cotyledon\"]\n",
    "time_point_n = len(time_point)\n",
    "time_point_id = {}\n",
    "for i in range(0,time_point_n):\n",
    "    time_point_id[time_point[i]] = i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "### read edge info \n",
    "edge = {}; node_all = []; node_each = {}; main_edge = set()\n",
    "\n",
    "file = open(\"endo_edge.txt\")\n",
    "for line in file:\n",
    "    l = line.rstrip().split('\\t')\n",
    "\n",
    "    if l[0] not in node_all:\n",
    "        node_all.append(l[0])\n",
    "    if l[1] not in node_all:\n",
    "        node_all.append(l[1])\n",
    "\n",
    "    edge[l[0]] = edge.get(l[0], [])\n",
    "    edge[l[0]].append(l[1])\n",
    "\n",
    "    num = time_point_id[l[0].split(':')[0]]\n",
    "    node_each[num] = node_each.get(num, [])\n",
    "    if l[0] not in node_each[num]:\n",
    "        node_each[num].append(l[0])\n",
    "\n",
    "    main_edge.add((l[0],l[1]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "### read edge weight file\n",
    "\n",
    "main_weight = {}; extra_weight = {}\n",
    "\n",
    "file = open(\"edge_prob.txt\")\n",
    "\n",
    "\n",
    "for line in file:\n",
    "\n",
    "    l = line.rstrip().split('\\t')\n",
    "\n",
    "    if float(l[2])>0.8:\n",
    "        xx = \"specific\"\n",
    "    elif float(l[2])>0.2:\n",
    "        xx = \"additional\"\n",
    "\n",
    "    if (l[0],l[1]) in main_edge:\n",
    "\n",
    "        if float(l[2]) > 0.2:\n",
    "            main_weight[l[1]] = float(l[2])\n",
    "        else:\n",
    "\n",
    "            main_weight[l[1]] = 0\n",
    "    else:\n",
    "        if float(l[2]) > 0.2:\n",
    "            extra_weight[(l[0],l[1])] = float(l[2])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "### read group information, used for the color of the node\n",
    "file = open(\"endo_celltype.list\")\n",
    "i = 1\n",
    "coor = {}\n",
    "node_group = {}\n",
    "for line in file:\n",
    "    l = line.rstrip().split(\"\\t\")\n",
    "    node_group[l[0]] = int(l[1])\n",
    "    coor[l[0]] = i\n",
    "    i += 1\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1_9_11h:CC\n",
      "1_9_11h:Syn\n"
     ]
    }
   ],
   "source": [
    "### create the info for all the node\n",
    "\n",
    "dat = {}\n",
    "\n",
    "for i in node_all:\n",
    "\n",
    "    dat[i] = {'name':i}\n",
    "\n",
    "    if i in edge:\n",
    "        dat[i]['children'] = []\n",
    "\n",
    "    if i in main_weight:\n",
    "        dat[i]['edge_weight'] = main_weight[i]\n",
    "    else:\n",
    "        print(i)\n",
    "\n",
    "    if i.split(':')[1] in coor:\n",
    "        dat[i]['fx'] = str(coor[i.split(':')[1]])\n",
    "    else:\n",
    "\n",
    "        print(i)\n",
    "\n",
    "    color_map = {\n",
    "        0: \"#ef6547\",   # \n",
    "        1: \"#FF0000\",   # \n",
    "        2: \"#FF8C00\",   # \n",
    "        3: \"#C2A289\",   # \n",
    "        4: \"#A46D2C\",   # \n",
    "        5: \"#9A9AF8\",   # \n",
    "        6: \"#dbdcde\",   # \n",
    "        7: \"#A4A5A7\",   # \n",
    "        8: \"#FAD1E0\",   # \n",
    "        9: \"#F683D8\",   # \n",
    "        10: \"#EF5D8C\",  # \n",
    "        11: \"#65C2A4\",  # \n",
    "        12: \"#1E803D\",  # \n",
    "        13: \"#9FB2DA\",  # \n",
    "        14: \"#1B79AF\",  # \n",
    "        15: \"#c2dcbf\",  # \n",
    "        16: \"#FBE5B8\",  # \n",
    "    }\n",
    "\n",
    "    if i.split(':')[1] in node_group:\n",
    "        dat[i]['node_group'] = color_map[node_group[i.split(':')[1]]]\n",
    "    else:\n",
    "        print(i)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extra weight dictionary: {}\n"
     ]
    }
   ],
   "source": [
    "print(\"Extra weight dictionary:\", extra_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for node in dat.values():\n",
    "    node['children'] = []\n",
    "\n",
    "\n",
    "for i in range(time_point_n-2, -1, -1): \n",
    "    if i in node_each: \n",
    "        for j in node_each[i]:\n",
    "            if j in edge:  \n",
    "                for k in edge[j]:\n",
    "                    if k in dat:  \n",
    "                        dat[j]['children'].append(dat[k])\n",
    "\n",
    "\n",
    "root_node = {'name': 'All', 'children': []}\n",
    "\n",
    "\n",
    "earliest_time_point = time_point[0]\n",
    "for node in node_each[time_point_id[earliest_time_point]]:\n",
    "    root_node['children'].append(dat[node])\n",
    "\n",
    "def add_children(node):\n",
    "    if 'children' in node:\n",
    "        new_children = []\n",
    "        for child in node['children']:\n",
    "            if child['name'] in edge:\n",
    "                child['children'] = [dat[child_name] for child_name in edge[child['name']] if child_name in dat]\n",
    "                add_children(child)\n",
    "            new_children.append(child)\n",
    "        node['children'] = new_children\n",
    "\n",
    "add_children(root_node)\n",
    "\n",
    "def remove_empty_children(node):\n",
    "    if 'children' in node:\n",
    "        if not node['children']:\n",
    "            del node['children']\n",
    "        else:\n",
    "            for child in node['children']:\n",
    "                remove_empty_children(child)\n",
    "\n",
    "remove_empty_children(root_node)\n",
    "\n",
    "with open(\"endo_0.5_0529v1.json\", 'w') as json_file:\n",
    "    json.dump(root_node, json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('endo.json', 'r') as file:\n",
    "    tree_data = json.load(file)\n",
    "\n",
    "\n",
    "def reorder_tree_data(node, depth=0):\n",
    "    if depth < len(node_order) and 'children' in node:\n",
    "\n",
    "        current_order = node_order[depth]\n",
    "\n",
    "        order_map = {name: index for index, name in enumerate(current_order)}\n",
    "\n",
    "        node['children'].sort(key=lambda x: order_map.get(x['name'], float('inf')))\n",
    "\n",
    "        for child in node['children']:\n",
    "            reorder_tree_data(child, depth + 1)\n",
    "\n",
    "reorder_tree_data(tree_data)\n",
    "\n",
    "def remove_empty_children(node):\n",
    "    if 'children' in node:\n",
    "        if not node['children']:\n",
    "            del node['children']\n",
    "        else:\n",
    "            for child in node['children']:\n",
    "                remove_empty_children(child)\n",
    "\n",
    "remove_empty_children(tree_data)\n",
    "\n",
    "with open('endo_0.5_reordered.json', 'w') as file:\n",
    "    json.dump(tree_data, file, ensure_ascii=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cellFlow",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
